{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment week 5: Attention"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4f11cfc508063ff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we import the necessary libraries and download the dataset. The dataset is split into Training and Testing. The reviews in the dataset are limited to max 250 words, and padding is added to fill in shorter reviews."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96e77bcd3cf9d0f"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.datasets import imdb\n",
    "\n",
    "# Dataset variables\n",
    "max_features = 10000 # vocabulary size\n",
    "max_len = 250 # words per sample \n",
    "\n",
    "# Creating the Training and Testing sets\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# Add padding to shorter reviews \n",
    "x_train = keras.utils.pad_sequences(x_train, maxlen=max_len, padding='post')\n",
    "x_test = keras.utils.pad_sequences(x_test, maxlen=max_len, padding='post')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-24T13:08:52.805734400Z",
     "start_time": "2025-11-24T13:08:48.641558800Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I tokenized the dataset, and made a list of the word indexes. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c000e488bbb11e6a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = dict((value, key) for (key, value) in word_to_index.items())\n",
    "\n",
    "example_review = \" \".join(index_to_word.get(i-3, \"?\") for i in x_train[0])\n",
    "print(example_review)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-24T13:08:52.895576300Z",
     "start_time": "2025-11-24T13:08:52.807742100Z"
    }
   },
   "id": "b4bd28240ee6db36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we define a custom layer to create the word vectors from the tokens. This layer takes into account the positions of the words within a sentence. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e192ca370fbdac84"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Embedding\n",
    "\n",
    "class TokenAndPositionEmbedding(Layer):\n",
    "    def __init__(self, seq_len, vocab_size, emb_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = Embedding(input_dim=vocab_size, output_dim=emb_dim)\n",
    "        self.pos_emb = Embedding(input_dim=seq_len, output_dim=emb_dim)\n",
    "\n",
    "    def call(self, x_input):\n",
    "        seq_len = keras.ops.shape(x_input)[-1]\n",
    "        positions = keras.ops.arange(start=0, stop=seq_len, step=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x_input = self.token_emb(x_input)\n",
    "        return x_input + positions\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-24T13:08:52.904602500Z",
     "start_time": "2025-11-24T13:08:52.894575200Z"
    }
   },
   "id": "fb0d46ee47810f29"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model architecture\n",
    "\n",
    "I separated the model into several blocks for clarity.\n",
    "\n",
    "Block 1: Inputs \n",
    "- Input\n",
    "- Tokenization (residual connection to Block 2)\n",
    "- MultiHeadAttention\n",
    "\n",
    "Block 2: Add & Norm 1\n",
    "- Add (combines output from Tokenization and MultiHeadAttention)\n",
    "- Normalization (residual connection to block 4)\n",
    "\n",
    "Block 3: FCN\n",
    "- Dense layer, 128 units (2x the second Dense) and ReLu activation\n",
    "- Dropout(0.1), small dropout to improve accuracy\n",
    "- Dense layer, 64 units (matching embed_dim) and no activation\n",
    "\n",
    "Block 4: Add & Norm 2\n",
    "- Add (combines output from FCN and Add & Norm 1)\n",
    "- Normalization\n",
    "\n",
    "Block 5: Outputs\n",
    "- GlobalAveragePooling1D + GlobalMaxPooling1D combined\n",
    "- Dropout\n",
    "- Output\n",
    "\n",
    "The model is compiled with Adam optimizer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb27924e6aa6c1ef"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"functional_4\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_6       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ -                 │\n│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ token_and_position… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m, \u001B[38;5;34m96\u001B[0m)   │    \u001B[38;5;34m984,000\u001B[0m │ input_layer_6[\u001B[38;5;34m0\u001B[0m]… │\n│ (\u001B[38;5;33mTokenAndPositionE…\u001B[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m, \u001B[38;5;34m96\u001B[0m)   │     \u001B[38;5;34m37,248\u001B[0m │ token_and_positi… │\n│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │            │ token_and_positi… │\n│                     │                   │            │ token_and_positi… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_10 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m, \u001B[38;5;34m96\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ multi_head_atten… │\n│                     │                   │            │ token_and_positi… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m, \u001B[38;5;34m96\u001B[0m)   │        \u001B[38;5;34m192\u001B[0m │ add_10[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_14 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m, \u001B[38;5;34m192\u001B[0m)  │     \u001B[38;5;34m18,624\u001B[0m │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_14          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m, \u001B[38;5;34m192\u001B[0m)  │          \u001B[38;5;34m0\u001B[0m │ dense_14[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_15 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m, \u001B[38;5;34m96\u001B[0m)   │     \u001B[38;5;34m18,528\u001B[0m │ dropout_14[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_11 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m, \u001B[38;5;34m96\u001B[0m)   │          \u001B[38;5;34m0\u001B[0m │ dense_15[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],   │\n│                     │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m250\u001B[0m, \u001B[38;5;34m96\u001B[0m)   │        \u001B[38;5;34m192\u001B[0m │ add_11[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m96\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ layer_normalizat… │\n│ (\u001B[38;5;33mGlobalAveragePool…\u001B[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_max_pooling… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m96\u001B[0m)        │          \u001B[38;5;34m0\u001B[0m │ layer_normalizat… │\n│ (\u001B[38;5;33mGlobalMaxPooling1…\u001B[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m192\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ global_average_p… │\n│ (\u001B[38;5;33mConcatenate\u001B[0m)       │                   │            │ global_max_pooli… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_15          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m192\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ concatenate_3[\u001B[38;5;34m0\u001B[0m]… │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_16 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │        \u001B[38;5;34m193\u001B[0m │ dropout_15[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ token_and_position… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">984,000</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionE…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │ token_and_positi… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ token_and_positi… │\n│                     │                   │            │ token_and_positi… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n│                     │                   │            │ token_and_positi… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ add_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,624</span> │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n│                     │                   │            │ layer_normalizat… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">250</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │ add_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dropout_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">193</span> │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,058,977\u001B[0m (4.04 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,058,977</span> (4.04 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,058,977\u001B[0m (4.04 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,058,977</span> (4.04 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.layers import Input, Dense, Concatenate,GlobalAveragePooling1D, GlobalMaxPooling1D, Dropout, Add, LayerNormalization\n",
    "from keras.models import Model\n",
    "from keras.layers import MultiHeadAttention\n",
    "\n",
    "num_heads = 3 # number of attention heads\n",
    "embed_dim = 96 # word embeddings dimension\n",
    "key_dim = embed_dim // num_heads # query/key dimension for one head\n",
    "\n",
    "# Inputs, tokenization and attention layer\n",
    "inputs = Input(shape=(max_len,))\n",
    "v = TokenAndPositionEmbedding(max_len, max_features, embed_dim)(inputs)\n",
    "attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=0.1)(v, v, v) \n",
    "\n",
    "# Add & Norm 1\n",
    "# Residual input from vectoring layer\n",
    "x = Add()([attention_output, v])\n",
    "x = LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "# Fully connected feedforward layer\n",
    "ff = Dense(embed_dim*2, activation=\"relu\")(x)\n",
    "ff = Dropout(0.1)(ff)\n",
    "ff = Dense(embed_dim)(ff)\n",
    "\n",
    "# Add & Norm 2\n",
    "# Residual input from Add & Norm 1\n",
    "x = Add()([ff, x])\n",
    "x = LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "# Pooling, Dropout and outputs\n",
    "x = Concatenate()([\n",
    "    GlobalAveragePooling1D()(x),\n",
    "    GlobalMaxPooling1D()(x)\n",
    "])\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-24T13:08:53.073635300Z",
     "start_time": "2025-11-24T13:08:52.904602500Z"
    }
   },
   "id": "49949323e85cc8ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model is trained for 5 epochs with batch size 32."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d61705972528eed"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m122s\u001B[0m 150ms/step - accuracy: 0.7686 - loss: 0.4772\n",
      "Epoch 2/5\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m115s\u001B[0m 147ms/step - accuracy: 0.8998 - loss: 0.2492\n",
      "Epoch 3/5\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m115s\u001B[0m 147ms/step - accuracy: 0.9342 - loss: 0.1769\n",
      "Epoch 4/5\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m117s\u001B[0m 150ms/step - accuracy: 0.9536 - loss: 0.1283\n",
      "Epoch 5/5\n",
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m116s\u001B[0m 149ms/step - accuracy: 0.9655 - loss: 0.0985\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x26a11c84810>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-24T13:18:38.735286500Z",
     "start_time": "2025-11-24T13:08:53.074631300Z"
    }
   },
   "id": "439a19162804e6d8"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m782/782\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m38s\u001B[0m 47ms/step - accuracy: 0.8544 - loss: 0.4292\n",
      "Test accuracy = 0.8544\n"
     ]
    }
   ],
   "source": [
    "print(f'Test accuracy = {model.evaluate(x_test, y_test)[1]:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-24T13:19:16.386323900Z",
     "start_time": "2025-11-24T13:18:38.741289500Z"
    }
   },
   "id": "906394005d8745b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final test accuracy of this model is 85,4%."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f395212518bc391c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
