{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment: week 4\n",
    "\n",
    "Using pre-trained word embeddings and understanding word vectors."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdc0263277453b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Variables and data download\n",
    "I tested with all versions of the glove data, and ended up using the smallest 50d version for shorter runtime. I also declared the word_dict variable here, which will be filled with the word vectors from the given file-"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98094d783fc3d3dc"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:35:43.051746600Z",
     "start_time": "2025-11-17T14:35:43.048532300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Path to file\n",
    "glove_path = \"./glove.2024.wikigiga/wiki_giga_2024_50.txt\"\n",
    "\n",
    "# Vector dictionary\n",
    "word_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset was loaded into a dictionary."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa50a13b404bc710"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vectors: 1291147\n"
     ]
    }
   ],
   "source": [
    "with open(glove_path, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.rstrip().split(\" \")\n",
    "        word = parts[0]\n",
    "        vector = np.asarray(parts[1:], dtype=\"float32\")\n",
    "        if vector.shape == (50,):\n",
    "            word_dict[word] = vector\n",
    "\n",
    "print(\"Loaded vectors:\", len(word_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:11.838834300Z",
     "start_time": "2025-11-17T14:35:43.055753400Z"
    }
   },
   "id": "49720c6d19223b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Functions\n",
    "I created some helper lists and dictionaries for later use with the functions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b22bb860c732fb3"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [],
   "source": [
    "# Creating a list of words\n",
    "words = list(word_dict.keys())\n",
    "\n",
    "# Adding indexes for words in dictionary\n",
    "word_to_index = {w: i for i, w in enumerate(words)}\n",
    "\n",
    "# Creating a matrix with the vectors\n",
    "vectors = np.stack([word_dict[w] for w in words])\n",
    "\n",
    "# Normalizing the matrix for cosine similarity\n",
    "norm_vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:14.414706Z",
     "start_time": "2025-11-17T14:36:11.833838700Z"
    }
   },
   "id": "6d96369554528da2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here I defined functions to get the closest word to query word, and a function that makes it faster to use. The function has an option to return multiple words as well, I used longer lists in testing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be4561d6225e8f9f"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "# Function to find the closest word. Option to return multiple.\n",
    "def closest_word(query_vector, skip=None, top_k=1):\n",
    "    # Normalize\n",
    "    q = query_vector / np.linalg.norm(query_vector)\n",
    "    \n",
    "    # Cosine similarity\n",
    "    sims = np.dot(norm_vectors, q)\n",
    "    \n",
    "    # Skip target words\n",
    "    if skip:\n",
    "        for w in skip:\n",
    "            if w in word_to_index:\n",
    "                sims[word_to_index[w]] = -1e9\n",
    "    \n",
    "    # Get k closest vectors\n",
    "    idx = np.argsort(-sims)[:top_k]\n",
    "    \n",
    "    # Return words based on index\n",
    "    return [words[i] for i in idx]\n",
    "\n",
    "# Function to get analogies with skipping query words\n",
    "def analogy(a, b, c):\n",
    "    return closest_word(\n",
    "        word_dict[a] - word_dict[b] + word_dict[c],\n",
    "        skip=[a,b,c])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:14.426209900Z",
     "start_time": "2025-11-17T14:36:14.418701900Z"
    }
   },
   "id": "4ac87552347ad565"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Getting word analogies\n",
    "First I printed the vector representations for the given words:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aafe68ba6b54f13c"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Man vector: [-1.217787e+00 -2.935390e-01 -4.390530e-01  6.924400e-02  2.682640e-01\n",
      " -1.988100e-01 -1.297030e-01  1.003629e+00  4.606740e-01 -7.343290e-01\n",
      "  3.579700e-02 -1.491620e-01  1.898410e-01 -1.992740e-01 -3.605320e-01\n",
      "  3.182900e-01  5.654690e-01 -3.085540e-01 -1.395550e-01  7.721380e-01\n",
      " -1.136440e-01  8.250330e-01  3.852980e-01 -1.178040e-01 -2.507190e-01\n",
      "  3.189500e-02  6.723400e-02  3.140840e-01 -8.328900e-02 -1.069440e-01\n",
      " -7.319130e-01 -8.047010e-01  3.093600e-02 -1.443550e-01  5.556690e-01\n",
      "  4.766830e-01  7.349810e-01  4.709278e+00  5.564010e-01 -2.346130e-01\n",
      "  1.162280e-01  9.931000e-03 -7.955820e-01  3.235500e-01 -6.286910e-01\n",
      " -3.320000e-04  6.728500e-02  8.380330e-01  7.360900e-02  1.323740e+00]\n",
      "Woman vector: [-1.632972e+00 -1.172860e-01 -1.332430e+00 -7.439910e-01  6.614890e-01\n",
      "  3.433440e-01 -1.023777e+00  4.300200e-01 -2.342020e-01 -3.084370e-01\n",
      "  2.529340e-01 -1.476390e-01  7.209500e-02 -1.603000e-01 -4.309100e-01\n",
      "  5.801640e-01 -1.318800e-02 -4.371610e-01 -5.224300e-02  6.352760e-01\n",
      "  5.037000e-03  1.137030e+00  3.665750e-01  7.453000e-02 -6.276670e-01\n",
      "  1.077510e-01 -2.284660e-01 -1.096450e-01  2.880530e-01  1.900550e-01\n",
      " -7.784380e-01 -2.502000e-01  1.409750e-01  2.853660e-01  3.327560e-01\n",
      "  1.428630e+00  9.529310e-01  4.291185e+00  1.631540e-01 -8.022370e-01\n",
      "  2.801480e-01 -5.140820e-01 -3.492600e-01 -8.820000e-04 -8.668610e-01\n",
      " -1.144490e-01 -7.283980e-01  1.127348e+00  3.048520e-01  8.999850e-01]\n",
      "King vector: [-0.39003   0.868335  0.684807 -0.758227  1.54142  -2.006612 -0.107967\n",
      "  1.26053   0.259971 -0.587266  1.167608  0.216386  0.712985 -0.514837\n",
      " -0.531705 -0.250713  0.272562  0.420457  0.422036  0.27177   0.284001\n",
      "  0.207707 -1.011175  0.179848  0.022646  0.190826  0.031093 -0.066455\n",
      " -1.041256 -0.207106 -0.603441 -0.189004  0.666082  0.122189 -0.373318\n",
      "  0.543726 -0.258834  3.978247  0.525289  0.927056 -0.609059 -0.553423\n",
      " -0.297424  0.271807  0.41184  -0.055333 -0.55883  -0.065188  1.167179\n",
      "  0.132492]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Man vector: {word_dict['man']}\")\n",
    "print(f\"Woman vector: {word_dict['woman']}\")\n",
    "print(f\"King vector: {word_dict['king']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:14.498890600Z",
     "start_time": "2025-11-17T14:36:14.426209900Z"
    }
   },
   "id": "9355489b9496ea78"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I tested the closest_word -function with the given words."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f081ac256e6b3ca7"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['king']\n",
      "['king']\n"
     ]
    }
   ],
   "source": [
    "# Trying the basic function with word \"King\"\n",
    "print(closest_word(word_dict['king']))\n",
    "\n",
    "# Trying the basic function with equation \n",
    "print(closest_word(word_dict[\"woman\"] - word_dict[\"man\"] + word_dict[\"king\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:15.007733700Z",
     "start_time": "2025-11-17T14:36:14.443856100Z"
    }
   },
   "id": "8d6207749e747af3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Without skipping words included in the query, the closest words are the queried words."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19c670ce3b2c6b74"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['queen']\n"
     ]
    }
   ],
   "source": [
    "# Using the function with skipping words in result\n",
    "print(analogy(\"woman\", \"man\", \"king\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:15.298344Z",
     "start_time": "2025-11-17T14:36:14.988737900Z"
    }
   },
   "id": "730afba24b3ceca4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "When the words included in the query are removed from the results, the resulting closest word is correct with the equation. Here the result \"queen\" reflects the word that has same relation to \"king\" as \"woman\" has to \"man\"."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d017cbf6afa9279"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Finding more interesting word vector relations\n",
    "I tried to find other word pairings that would give a sensible result. Many words I tried ended up with just words similar to the last query parameter, without any effect from the two first words. Here are some that gave interesting results:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63e8d8da4574b972"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['daughter']\n"
     ]
    }
   ],
   "source": [
    "print(analogy(\"woman\",\"man\",\"son\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:15.624286600Z",
     "start_time": "2025-11-17T14:36:15.289350700Z"
    }
   },
   "id": "15d54f49f2e197f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The gendered word associations seem to work well."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c63b2e0e50875604"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['berlin']\n"
     ]
    }
   ],
   "source": [
    "print(analogy(\"paris\",\"france\",\"germany\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:15.933936Z",
     "start_time": "2025-11-17T14:36:15.609278800Z"
    }
   },
   "id": "47c66f457648b79a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Many tries with country names and capitals went into loop with just more country names, but \"paris\" seems to be strong enough city that it takes us to german cities. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d07fcbcc5e51c3f5"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beer']\n"
     ]
    }
   ],
   "source": [
    "print(analogy(\"wine\",\"france\",\"germany\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:16.267795200Z",
     "start_time": "2025-11-17T14:36:15.931940100Z"
    }
   },
   "id": "ca7cbc03ccef2570"
  },
  {
   "cell_type": "markdown",
   "source": [
    "National drinking habits seem to come through in the word analogies."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1e71e5faf5185c3"
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['college']\n"
     ]
    }
   ],
   "source": [
    "print(analogy(\"school\", \"child\", \"adult\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:36:16.611912500Z",
     "start_time": "2025-11-17T14:36:16.250793100Z"
    }
   },
   "id": "648c11b8a620b69f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "I was afraid that this would give out \"work\", but different school levels seem to be clustered well in the matrix."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c52ced64d709e88b"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mansion']\n",
      "['apple']\n"
     ]
    }
   ],
   "source": [
    "print(analogy(\"apartment\", \"poor\", \"rich\"))\n",
    "print(analogy(\"pc\", \"poor\", \"rich\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-11-17T14:40:38.980798800Z",
     "start_time": "2025-11-17T14:40:38.454781300Z"
    }
   },
   "id": "a50b81a9bf5d404a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The word vectors seem to reflect the income level gap between different items."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3369029135c6384d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
